# OpenClaw å®‰è£èˆ‡é…ç½®æŒ‡å—

OpenClaw æ˜¯ä¸€å€‹å¼·å¤§çš„ AI åŠ©æ‰‹æ¡†æ¶ï¼Œå¯ä»¥é€é Telegram é ç«¯æ§åˆ¶ä½ çš„ä¼ºæœå™¨ï¼ŒåŸ·è¡Œå„ç¨®ç³»çµ±æŒ‡ä»¤ã€‚æœ¬æŒ‡å—å°‡å¸¶ä½ å®Œæˆå¾å®‰è£åˆ°é€é iPhone Telegram æ‡‰ç”¨ç¨‹å¼é ç«¯æŸ¥è©¢ç³»çµ±è³‡è¨Šçš„å®Œæ•´æµç¨‹ã€‚

## ğŸ“‹ å‰ç½®éœ€æ±‚

- Docker å’Œ Docker Compose
- Telegram å¸³è™Ÿ
- Ollamaï¼ˆç”¨æ–¼é‹è¡Œæœ¬åœ° LLM æ¨¡å‹ï¼‰
- å…·å‚™ NVIDIA GPU çš„ä¼ºæœå™¨ï¼ˆå¦‚éœ€æŸ¥è©¢é¡¯å¡è³‡è¨Šï¼‰

## ğŸš€ å®‰è£æ­¥é©Ÿ

### 1. å®‰è£ Ollama

é¦–å…ˆå®‰è£ Ollama ä¾†é‹è¡Œæœ¬åœ°èªè¨€æ¨¡å‹ï¼š

```bash
# Linux
curl -fsSL https://ollama.com/install.sh | sh

# macOS
brew install ollama
```

å•Ÿå‹• Ollama æœå‹™ï¼š

```bash
ollama serve
```

### 2. ä¸‹è¼‰ä¸¦é…ç½® AI æ¨¡å‹

ä½¿ç”¨ Ollama ä¸‹è¼‰ OpenClaw å®˜æ–¹æ¨è–¦çš„æ¨¡å‹ï¼š

```bash
# å®˜æ–¹æ¨è–¦æ¨¡å‹ï¼ˆé¸æ“‡å…¶ä¸­ä¸€å€‹ï¼‰

# Qwen3 Coderï¼ˆæ¨è–¦ - å°ˆç‚ºç¨‹å¼ç¢¼å’ŒæŒ‡ä»¤å„ªåŒ–ï¼‰
# é è¨­ç‰ˆæœ¬ (30B æ¨¡å‹ï¼Œ19GBï¼Œ256K ä¸Šä¸‹æ–‡)
ollama pull qwen3-coder

# æˆ–æŒ‡å®šç‰ˆæœ¬
ollama pull qwen3-coder:latest  # 30B ç‰ˆæœ¬
ollama pull qwen3-coder:30b     # 30B ç‰ˆæœ¬ï¼ˆèˆ‡ latest ç›¸åŒï¼‰

# GLM 4.7ï¼ˆè¼•é‡ç´šé«˜æ•ˆèƒ½æ¨¡å‹ï¼‰
ollama pull glm-4.7

# GPT OSS 20Bï¼ˆå¤§å‹é–‹æºæ¨¡å‹ï¼‰
ollama pull gpt-oss:20b
```

> **æ¨¡å‹è¦æ ¼åƒè€ƒ**:
> - `qwen3-coder:30b` - 19GB, 256K ä¸Šä¸‹æ–‡é•·åº¦, æ–‡å­—è¼¸å…¥
> - è©³ç´°è³‡è¨Š: [Ollama qwen3-coder æ¨¡å‹åº«](https://ollama.com/library/qwen3-coder)

é©—è­‰æ¨¡å‹æ˜¯å¦æˆåŠŸå®‰è£ï¼š

```bash
ollama list
```

æ¸¬è©¦æ¨¡å‹é‹è¡Œï¼š

```bash
# ä½¿ç”¨ qwen3-coder æ¸¬è©¦
ollama run qwen3-coder "ä½ å¥½ï¼Œè«‹ä»‹ç´¹è‡ªå·±"
```

### 3. å®‰è£ OpenClaw

è¨ªå• [OpenClaw å®˜æ–¹ç¶²ç«™](https://openclaw.ai/) ç²å–æœ€æ–°å®‰è£æŒ‡ä»¤ã€‚

ä½¿ç”¨ Docker Compose å®‰è£ï¼ˆæ¨è–¦ï¼‰ï¼š

```bash
# å‰µå»ºå°ˆæ¡ˆç›®éŒ„
mkdir openclaw && cd openclaw

# ä¸‹è¼‰ docker-compose.yml
curl -O https://openclaw.ai/docker-compose.yml

# ç·¨è¼¯é…ç½®æª”æ¡ˆ
nano docker-compose.yml
```

åŸºæœ¬ `docker-compose.yml` é…ç½®ç¯„ä¾‹ï¼š

```yaml
version: '3.8'

services:
  openclaw:
    image: openclaw/openclaw:latest
    container_name: openclaw
    restart: unless-stopped
    environment:
      - OLLAMA_HOST=http://host.docker.internal:11434
      - MODEL_NAME=qwen3-coder  # ä½¿ç”¨å®˜æ–¹æ¨è–¦æ¨¡å‹
    volumes:
      - ./data:/app/data
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - "8080:8080"
    extra_hosts:
      - "host.docker.internal:host-gateway"
```

å•Ÿå‹• OpenClaw æœå‹™ï¼š

```bash
docker-compose up -d
```

æª¢æŸ¥æœå‹™ç‹€æ…‹ï¼š

```bash
docker-compose logs -f
```

## ğŸ¤– è¨­å®š Telegram Bot èˆ‡é…å° {id="telegram-bot-setup"}

### 1. å‰µå»º Telegram Bot

1. åœ¨ Telegram ä¸­æœå°‹ `@BotFather`
2. ç™¼é€ `/newbot` å‘½ä»¤
3. æŒ‰ç…§æç¤ºè¨­å®š Bot åç¨±å’Œä½¿ç”¨è€…åç¨±
4. ä¿å­˜ BotFather æä¾›çš„ **API Token**ï¼ˆæ ¼å¼ï¼š`123456:ABC-DEF1234ghIkl-zyx57W2v1u123ew11`ï¼‰

### 2. é…ç½® Telegram Bot Token

å°‡ä½ çš„ Telegram Bot Token æ·»åŠ åˆ° OpenClaw é…ç½®ï¼š

```bash
# æ–¹æ³• 1: ç’°å¢ƒè®Šæ•¸ï¼ˆåœ¨ docker-compose.yml ä¸­æ·»åŠ ï¼‰
environment:
  - TELEGRAM_BOT_TOKEN=ä½ çš„Bot Token

# æ–¹æ³• 2: é€éæŒ‡ä»¤è¨­å®š
docker exec -it openclaw openclaw config set telegram.bot_token "ä½ çš„Bot Token"
```

é‡å•Ÿæœå‹™ä½¿é…ç½®ç”Ÿæ•ˆï¼š

```bash
docker-compose restart
```

## ğŸ“± é…å° Telegram Botï¼ˆé‡è¦ï¼‰{id="telegram-bot-pairing"}

> **å®˜æ–¹æ–‡æª”åƒè€ƒ**: [OpenClaw Pairing é…å°æŒ‡å—](https://docs.openclaw.ai/channels/pairing)

### 1. åœ¨ Telegram æ‡‰ç”¨ä¸­ç²å–é…å°ç¢¼

1. é–‹å•Ÿ iPhone ä¸Šçš„ Telegram æ‡‰ç”¨ï¼ˆå°é£›æ©Ÿ Appï¼‰
2. æœå°‹ä¸¦é–‹å•Ÿä½ å‰›å‰µå»ºçš„ Botï¼ˆä½¿ç”¨ Bot çš„ä½¿ç”¨è€…åç¨±ï¼Œä¾‹å¦‚ `@YourBotName_bot`ï¼‰
3. ç™¼é€ `/start` å‘½ä»¤

Bot æœƒè‡ªå‹•å›è¦†ä¸¦é¡¯ç¤ºé…å°ç¢¼ï¼Œé¡ä¼¼ï¼š

```
Welcome to OpenClaw! ğŸ¤–

Your pairing code is: ABCD-1234-EFGH-5678

Please run this command on your server to complete pairing:
openclaw pair verify ABCD-1234-EFGH-5678

This code will expire in 10 minutes.
```

### 2. åœ¨ä¼ºæœå™¨ç«¯é©—è­‰é…å°ç¢¼ {id="verify-pairing-server"}

è¤‡è£½ Bot é¡¯ç¤ºçš„é…å°ç¢¼ï¼Œç„¶å¾Œåœ¨ OpenClaw ä¼ºæœå™¨ä¸ŠåŸ·è¡Œé©—è­‰æŒ‡ä»¤ï¼š

```bash
# ä½¿ç”¨ Bot æä¾›çš„é…å°ç¢¼é€²è¡Œé…å°
docker exec -it openclaw openclaw pair verify ABCD-1234-EFGH-5678
```

æˆåŠŸé…å°å¾Œï¼Œçµ‚ç«¯æœƒé¡¯ç¤ºï¼š

```
âœ… Pairing successful!
User @your_telegram_username is now authorized.
```

åŒæ™‚ï¼ŒTelegram Bot ä¹Ÿæœƒç™¼é€ç¢ºèªè¨Šæ¯ï¼š

```
âœ… Pairing successful!
You can now send commands to control your server.
```

### 3. æª¢æŸ¥é…å°ç‹€æ…‹

æŸ¥çœ‹å·²é…å°çš„ç”¨æˆ¶æ¸…å–®ï¼š

```bash
# æŸ¥çœ‹æ‰€æœ‰å·²æˆæ¬Šçš„ç”¨æˆ¶
docker exec -it openclaw openclaw pair list

# æˆ–æŸ¥çœ‹é…å°è©³ç´°è³‡è¨Š
docker exec -it openclaw openclaw user list
```

## ğŸ’» ä½¿ç”¨ç¯„ä¾‹

### æŸ¥è©¢ NVIDIA é¡¯å¡è³‡è¨Š

é…å°æˆåŠŸå¾Œï¼Œåœ¨ Telegram ä¸­ç›´æ¥å‘ Bot ç™¼é€è‡ªç„¶èªè¨€æŒ‡ä»¤ï¼š

```
æŸ¥è©¢é¡¯å¡è³‡è¨Š
```

æˆ–

```
é¡¯ç¤º nvidia-smi
```

Bot æœƒåŸ·è¡Œ `nvidia-smi` æŒ‡ä»¤ä¸¦è¿”å›çµæœï¼š

```
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 4090        Off | 00000000:01:00.0  On |                  Off |
|  0%   45C    P8              20W / 450W |   1234MiB / 24564MiB |      2%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
```

### å…¶ä»–å¯¦ç”¨æŒ‡ä»¤ç¯„ä¾‹

```
# ç³»çµ±è³‡æºç›£æ§
é¡¯ç¤º CPU å’Œè¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³

# Docker å®¹å™¨ç®¡ç†
åˆ—å‡ºæ‰€æœ‰é‹è¡Œä¸­çš„å®¹å™¨

# ç£ç¢Ÿç©ºé–“æª¢æŸ¥
æª¢æŸ¥ç£ç¢Ÿä½¿ç”¨é‡

# æœå‹™ç‹€æ…‹æª¢æŸ¥
æŸ¥çœ‹æœå‹™ç‹€æ…‹
```

## ğŸ”’ å®‰å…¨æ€§è¨­å®š

### é™åˆ¶æŒ‡ä»¤åŸ·è¡Œæ¬Šé™

ç·¨è¼¯ OpenClaw é…ç½®æª”æ¡ˆä»¥é™åˆ¶å¯åŸ·è¡Œçš„æŒ‡ä»¤ï¼š

```bash
docker exec -it openclaw nano /app/config/permissions.yml
```

ç¯„ä¾‹é…ç½®ï¼š

```yaml
permissions:
  allowed_commands:
    - nvidia-smi
    - docker ps
    - df -h
    - free -h
    - uptime
  blocked_commands:
    - rm
    - shutdown
    - reboot
```

### è¨­å®šç”¨æˆ¶ç™½åå–®

åªå…è¨±ç‰¹å®š Telegram ç”¨æˆ¶ä½¿ç”¨ï¼š

```bash
docker exec -it openclaw openclaw user add @your_telegram_username
```

## ğŸ› ï¸ æ•…éšœæ’é™¤

### Ollama é€£ç·šå•é¡Œ

å¦‚æœ OpenClaw ç„¡æ³•é€£æ¥åˆ° Ollamaï¼š

```bash
# æª¢æŸ¥ Ollama æ˜¯å¦é‹è¡Œ
curl http://localhost:11434/api/version

# æª¢æŸ¥ Docker ç¶²è·¯
docker network inspect bridge
```

### Bot ç„¡å›æ‡‰ {id="bot-no-response"}

1. æª¢æŸ¥ Bot Token æ˜¯å¦æ­£ç¢ºè¨­å®š
2. ç¢ºèª OpenClaw å®¹å™¨æ­£åœ¨é‹è¡Œï¼š
   ```bash
   docker ps | grep openclaw
   ```
3. æŸ¥çœ‹éŒ¯èª¤æ—¥èªŒï¼š
   ```bash
   docker logs openclaw --tail 100
   ```

### é…å°ç¢¼éæœŸ

é…å°ç¢¼é€šå¸¸åœ¨ 10 åˆ†é˜å¾ŒéæœŸã€‚å¦‚æœéæœŸï¼Œè«‹é‡æ–°åŸ·è¡Œé…å°æµç¨‹ï¼š

1. åœ¨ Telegram Bot ä¸­é‡æ–°ç™¼é€ `/start` ç²å–æ–°çš„é…å°ç¢¼
2. åœ¨ä¼ºæœå™¨ä¸Šä½¿ç”¨æ–°çš„é…å°ç¢¼åŸ·è¡Œé©—è­‰ï¼š
   ```bash
   docker exec -it openclaw openclaw pair verify æ–°çš„é…å°ç¢¼
   ```

### ç„¡æ³•ç²å–é…å°ç¢¼

å¦‚æœ Bot æ²’æœ‰å›æ‡‰æˆ–ç„¡æ³•é¡¯ç¤ºé…å°ç¢¼ï¼š

1. ç¢ºèª Bot Token å·²æ­£ç¢ºè¨­å®šåœ¨ OpenClaw é…ç½®ä¸­
2. æª¢æŸ¥ OpenClaw æœå‹™æ˜¯å¦æ­£å¸¸é‹è¡Œ
3. é‡å•Ÿ OpenClaw æœå‹™ï¼š
   ```bash
   docker-compose restart
   ```

## ğŸ“š é€²éšé…ç½®

### è‡ªè¨‚æ¨¡å‹åƒæ•¸

èª¿æ•´æ¨¡å‹çš„é‹è¡Œåƒæ•¸ä»¥å„ªåŒ–æ€§èƒ½ï¼š

```yaml
environment:
  - MODEL_NAME=qwen3-coder  # æˆ– glm-4.7, gpt-oss:20b
  - MODEL_TEMPERATURE=0.7
  - MODEL_MAX_TOKENS=2048
  - MODEL_CONTEXT_LENGTH=4096
```

### è¨­å®šå¤šå€‹ Bot {id="multiple-bots"}

å¯ä»¥ç‚ºä¸åŒç”¨é€”å‰µå»ºå¤šå€‹ Bot å¯¦ä¾‹ï¼š

```yaml
services:
  openclaw-admin:
    image: openclaw/openclaw:latest
    environment:
      - TELEGRAM_BOT_TOKEN=ç®¡ç†Bot Token
      - ROLE=admin
  
  openclaw-monitor:
    image: openclaw/openclaw:latest
    environment:
      - TELEGRAM_BOT_TOKEN=ç›£æ§Bot Token
      - ROLE=monitor
```

## ğŸ”— ç›¸é—œè³‡æº

- [OpenClaw å®˜æ–¹ç¶²ç«™](https://openclaw.ai/)
- [OpenClaw GitHub Repository](https://github.com/openclaw/openclaw)
- [OpenClaw Pairing é…å°æŒ‡å—](https://docs.openclaw.ai/channels/pairing) - å®˜æ–¹é…å°æ–‡æª”
- [Ollama OpenClaw æ•´åˆæ–‡æª”](https://docs.ollama.com/integrations/openclaw) - å®˜æ–¹æ•´åˆæŒ‡å—
- [Ollama qwen3-coder æ¨¡å‹åº«](https://ollama.com/library/qwen3-coder) - æ¨¡å‹è©³ç´°è¦æ ¼
- [Ollama å®˜æ–¹æ–‡æª”](https://ollama.com/docs)
- [Telegram Bot API æ–‡æª”](https://core.telegram.org/bots/api)

## ğŸ“ ç¸½çµ

é€éä»¥ä¸Šæ­¥é©Ÿï¼Œä½ å·²ç¶“æˆåŠŸï¼š

1. âœ… å®‰è£ä¸¦é…ç½® Ollama èˆ‡å®˜æ–¹æ¨è–¦æ¨¡å‹ï¼ˆqwen3-coder / glm-4.7 / gpt-oss:20bï¼‰
2. âœ… éƒ¨ç½² OpenClaw ä¼ºæœå™¨
3. âœ… å‰µå»ºä¸¦é…å° Telegram Bot
4. âœ… åœ¨ iPhone Telegram æ‡‰ç”¨ä¸­é ç«¯æ§åˆ¶ä¼ºæœå™¨

ç¾åœ¨ä½ å¯ä»¥éš¨æ™‚éš¨åœ°é€é Telegram æŸ¥è©¢ä¼ºæœå™¨ç‹€æ…‹ã€ç®¡ç†æœå‹™ï¼Œäº«å— AI é©…å‹•çš„æ™ºèƒ½é‹ç¶­é«”é©—ï¼





